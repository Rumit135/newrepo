{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5ed35976eaac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import keras\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Flatten          \n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# data=mnist.load_data()\n",
    "\n",
    "# len(data)\n",
    "\n",
    "# len(data[0])\n",
    "\n",
    "# (x_train,y_train),(x_test,y_test)=data\n",
    "\n",
    "# x_train.shape\n",
    "\n",
    "# x_train[0].shape\n",
    "\n",
    "# plt.imshow(x_train[1],cmap=\"gray\")\n",
    "# # y_train[1]\n",
    "\n",
    "# num_of_samples=[]\n",
    "# cols=5\n",
    "# num_classes=10\n",
    "# fig,axs =plt.subplots(nrows=num_classes,ncols=cols,figsize=(5,10))\n",
    "# fig.tight_layout()\n",
    "# for i in range(cols):\n",
    "#     for j in range(num_classes):\n",
    "#         x_selected=x_train[y_train==j]\n",
    "#         var=random.randint(0,(len(x_selected)-1))\n",
    "#         axs[j][i].imshow(x_selected[var],cmap=\"gray\")\n",
    "#         axs[j][i].axis(\"off\")\n",
    "#         if i ==2:\n",
    "#             axs[j][i].set_title(str(j))\n",
    "#             num_of_samples.append(len(x_selected))\n",
    "\n",
    "# print(num_of_samples)\n",
    "# plt.figure(figsize=(12,4))\n",
    "# plt.bar(range(0,num_classes),num_of_samples)\n",
    "# plt.title(\"Distribution of the train dataset\")\n",
    "# plt.xlabel(\"class number\")\n",
    "# plt.ylabel(\"Number of images\")\n",
    "# plt.show()\n",
    "\n",
    "# x_train=x_train.reshape(-1,28,28,1)\n",
    "# x_test=x_test.reshape(-1,28,28,1)\n",
    "\n",
    "\n",
    "# y_train=to_categorical(y_train,10)\n",
    "# y_test=to_categorical(y_test,10)\n",
    "\n",
    "# y_train[5]\n",
    "\n",
    "# x_train=x_train/255\n",
    "# x_test=x_test/255\n",
    "\n",
    "# def le_net():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(30,(5,5),input_shape=(28,28,1),activation=\"relu\"))\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Conv2D(15,(3,3),activation=\"relu\"))\n",
    "#     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(500,activation=\"relu\"))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(num_classes,activation=\"softmax\"))\n",
    "#     model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "#     return model\n",
    "\n",
    "# lenet=le_net()\n",
    "# lenet.summary()\n",
    "\n",
    "# history=lenet.fit(x_train,y_train,epochs=8,validation_split=0.1,batch_size=400,verbose=1,shuffle=1)\n",
    "\n",
    "# plt.plot(history.history[\"loss\"])\n",
    "# plt.plot(history.history[\"val_loss\"])\n",
    "# plt.legend([\"loss\",\"val_loss\"])\n",
    "# plt.title(\"Loss\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "\n",
    "# plt.plot(history.history[\"acc\"])\n",
    "# plt.plot(history.history[\"val_acc\"])\n",
    "# plt.legend([\"acc\",\"val_acc\"])\n",
    "# plt.title(\"acc\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "\n",
    "# import requests\n",
    "# import io\n",
    "# import cv2 as cv\n",
    "# from PIL import Image\n",
    "# img=requests.get(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRRuqbZ7swv3hcKByIo9p5vnT9LIzuIvPd05s5nJdcxGT_k8DIl\",stream=True).content\n",
    "# array=io.BytesIO(img)\n",
    "# img1=Image.open(array).convert(\"L\")\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# data=np.array(img1)\n",
    "# plt.imshow(data)\n",
    "\n",
    "# data=cv.resize(data,(28,28))\n",
    "\n",
    "\n",
    "# data=data.reshape(1,28,28,1)\n",
    "\n",
    "# data=data/255\n",
    "\n",
    "# lenet.predict_classes(data)\n",
    "\n",
    "# lenet.predict(data)\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "link=\"https://drive.google.com/open?id=1hrTZGDX27Uqxcjt762GeMH11NeOgPUtp\"\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "print (id) # Verify that you\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# downloaded = drive.CreateFile({'id':id}) \n",
    "# downloaded.GetContentFile('Meta.csv')  \n",
    "# df3 = pd.read_csv('Meta.csv')\n",
    "\n",
    "# df3[\"Path\"].values[0]\n",
    "\n",
    "# from io import BytesIO\n",
    "# uploaded = files.upload()\n",
    "# im = Image.open(BytesIO(uploaded['o.png']))\n",
    "\n",
    "!pwd\n",
    "\n",
    "!ls\n",
    "\n",
    "!mkdir datasets\n",
    "\n",
    "!ls\n",
    "\n",
    "!cp -r /content/drive/My\\ Drive/gtsrb-german-traffic-sign /content/datasets\n",
    "\n",
    "!ls datasets\n",
    "\n",
    "import pandas as pd\n",
    "basedir=\"/content/datasets/gtsrb-german-traffic-sign/\"\n",
    "pd.read_csv(basedir+\"Test.csv\")\n",
    "\n",
    "!mkdir /content/datasets/gtsrb-german-traffic-sign/Train\n",
    "!tar -xvf /content/datasets/gtsrb-german-traffic-sign/Train.tar -C /content/datasets/gtsrb-german-traffic-sign/Train\n",
    "\n",
    "# !rm -r /content/datasets/gtsrb-german-traffic-sign/\n",
    "\n",
    "!mkdir /content/datasets/gtsrb-german-traffic-sign/Test\n",
    "!tar -xvf /content/datasets/gtsrb-german-traffic-sign/Test.tar -C /content/datasets/gtsrb-german-traffic-sign/Test\n",
    "\n",
    "import os\n",
    "os.listdir(basedir+\"Train\")\n",
    "df=pd.read_csv(basedir+\"Train.csv\")\n",
    "dt=df.loc[:,[\"ClassId\",\"Path\"]]\n",
    "\n",
    "images=[]\n",
    "labels=[]\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "for slot in dt.values:\n",
    "    im=Image.open(basedir+slot[1])\n",
    "    images.append(np.array(im))\n",
    "    labels.append(slot[0])\n",
    "train={\"images\":images,\"labels\":labels}\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(images[100])\n",
    "len(labels)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(basedir+\"Train.pkl\",\"wb\") as f:\n",
    "    f.write(pickle.dumps(train))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
